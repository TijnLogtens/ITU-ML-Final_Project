{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be applying the CART-algorithm (which uses a Gini impurity as a splitting criterion).\n",
    "The CART-algorithm is the current standard for building classification trees, and is also as the default by scikit-learn. Other options included ID3 and C4.5.\n",
    "\n",
    "CART is very similar to C4.5, though instead of building a tree with an undetermined amount of branches CART builds a binary tree. CART also uses the Gini impurity to determine what condition to slit the node on, instead of using regular information gain.\n",
    "\n",
    "We will still calculate the information gain, though it will now be in the form of a probabilistic function based of of the Gini impurity.\n",
    "\n",
    "Gini impurity is more commonly known as a method to show the disparity in wealth between two classes but it can be generalised a bit to show the disparity between the amount of values in one class and all others. So the more classes that arrive at a note, the higher the impurity.\n",
    "\n",
    "CART decides the root node by exhaustively trying all possible splitting conditions for their Gini impurity, which takes a little while because our data is sporadic and has floats for data points. Meaning it has to test every none duplicate value in afeature that's being considered for a question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 7, 6, 7, 3, 1, 2, 1, 2, 1, 2, 2, 1, 1, 7, 2, 2, 7, 5, 7,\n",
       "       3, 2, 3, 2, 6, 2, 1, 2, 2, 1, 3, 1, 7, 1, 5, 7, 1, 2, 1, 1, 7, 1,\n",
       "       5, 2, 5, 2, 6, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 7, 1, 2, 3, 2, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"Final_project_DATA/df_train.csv\")\n",
    "test = pd.read_csv(\"Final_project_DATA/df_test.csv\")\n",
    "\n",
    "test.iloc[:]['type'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the occurences of every label in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occ_labels(data):\n",
    "    # Counts the amount of occurences in a pandas series.\n",
    "    out = {}\n",
    "    labels = data['type'].to_numpy()\n",
    "    val, occ = np.unique(labels, return_counts=True)\n",
    "    for A, B in zip(val, occ):\n",
    "        out[A] = B\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 49, 2: 53, 3: 12, 5: 9, 6: 6, 7: 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_occ_labels(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create the split condition object class\n",
    "\n",
    "The split condition should hold the feature(column number) and the threshold/value that will be used as the condition.\n",
    "It also needs a method to compare the question value against the value of the passed sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitCondition:\n",
    "    def __init__(self, feature, threshold):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def compare(self, sample):\n",
    "        # Take sample value for feature, compare with threshold\n",
    "        s_value = sample[self.feature]\n",
    "        if isinstance(s_value,float) or isinstance(s_value,int):\n",
    "            return s_value >= self.threshold\n",
    "        else:\n",
    "            return s_value == self.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a method to split the dataset based on the questions.\n",
    "So we need to divide the samples in X into true and false samples.\n",
    "Or more concretely, into the values that will proceed to it's left and right child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, SplitCondition):\n",
    "    # Bad practise to append to DataFrames, so work with lists\n",
    "    trueSamples = []\n",
    "    falseSamples = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if SplitCondition.compare(data.iloc[i]):\n",
    "            trueSamples.append(data.iloc[i])\n",
    "        else:\n",
    "            falseSamples.append(data.iloc[i])\n",
    "    return pd.DataFrame(trueSamples), pd.DataFrame(falseSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function to assign a value to the quality of the node, a means to compare a questions to others. \n",
    "CART uses the Gini Impurity for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(samples):\n",
    "    cnt = count_occ_labels(samples)\n",
    "    impurity = 1\n",
    "    for i in cnt:\n",
    "        probability = cnt[i]/float(len(samples))\n",
    "        impurity -= probability**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Gini properly, we need to minimise the information gain compared to the node's child nodes. We need to know the uncertainty of the node and the impurity of the two new child nodes which will be introduced based on the question we're considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGain(true, false, previous):\n",
    "    p = float(len(true)) / (len(true) + len(false))\n",
    "    return previous - p * gini(true) - (1 - p) * gini(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the best vondition by trying every possible question and see what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestCondition(samples):\n",
    "    mostGains = 0 \n",
    "    bestCondition = None \n",
    "    previous = gini(samples) # needed for IG \n",
    "    n = samples.shape[1] - 1 # number of features\n",
    "    \n",
    "    for i in range(n):\n",
    "        uniques = samples.iloc[:,i].unique()\n",
    "        \n",
    "        for j in uniques:\n",
    "            condition = SplitCondition(samples.columns[i], j) \n",
    "            trueSamples, falseSamples = split(samples, condition)\n",
    "            \n",
    "            if len(trueSamples.index) == 0 or len(falseSamples.index) == 0: \n",
    "                continue\n",
    "                \n",
    "            gains = InformationGain(trueSamples, falseSamples, previous)\n",
    "            if gains > mostGains:\n",
    "                mostGains, bestCondition = gains, condition\n",
    "                \n",
    "    return mostGains, bestCondition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the nodes and leafs and a method to build the tree at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, samples):\n",
    "        self.pred = count_occ_labels(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, condition, left, right):\n",
    "        self.condition = condition\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treebuilder just recursively creates splits in the data until there's no more information gain, at which point it puts a leaf down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Treebuilder(samples,height=10000,nodes=1):\n",
    "    gain, condition = BestCondition(samples)\n",
    "    \n",
    "    if gain == 0 or math.floor(math.log(nodes,2)) == height:\n",
    "        print(nodes)\n",
    "        return Leaf(samples)\n",
    "    \n",
    "    trueSamples, falseSamples = split(samples, condition)\n",
    "    nodes += 2\n",
    "    \n",
    "    left = Treebuilder(trueSamples, height, nodes)\n",
    "    right = Treebuilder(falseSamples, height, nodes)\n",
    "    \n",
    "    return Node(condition, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "15\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "15\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "15\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "tree = Treebuilder(train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(math.floor(math.log(9,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need to classify based on the just now generated nodes and their branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sample, Node):\n",
    "    if isinstance(Node, Leaf):\n",
    "        return Node.pred\n",
    "    \n",
    "    if Node.condition.compare(sample):\n",
    "        return classify(sample, Node.left)\n",
    "    else:\n",
    "        return classify(sample, Node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1\n",
      "\n",
      " True Pos  : 17     False Pos : 12\n",
      "\n",
      " False Neg : 4     True Neg  : 32\n",
      "\n",
      "\n",
      "Type =  1\n",
      "Recall =  0.8095238095238095\n",
      "Precision =  0.5862068965517241\n",
      "\n",
      "\n",
      "Class 2\n",
      "\n",
      " True Pos  : 13     False Pos : 2\n",
      "\n",
      " False Neg : 10     True Neg  : 40\n",
      "\n",
      "\n",
      "Type =  2\n",
      "Recall =  0.5652173913043478\n",
      "Precision =  0.8666666666666667\n",
      "\n",
      "\n",
      "Class 3\n",
      "\n",
      " True Pos  : 0     False Pos : 3\n",
      "\n",
      " False Neg : 5     True Neg  : 57\n",
      "\n",
      "\n",
      "Type =  3\n",
      "Recall =  0.0\n",
      "Precision =  0.0\n",
      "\n",
      "\n",
      "Class 5\n",
      "\n",
      " True Pos  : 4     False Pos : 3\n",
      "\n",
      " False Neg : 0     True Neg  : 58\n",
      "\n",
      "\n",
      "Type =  5\n",
      "Recall =  1.0\n",
      "Precision =  0.5714285714285714\n",
      "\n",
      "\n",
      "Class 6\n",
      "\n",
      " True Pos  : 2     False Pos : 2\n",
      "\n",
      " False Neg : 1     True Neg  : 60\n",
      "\n",
      "\n",
      "Type =  6\n",
      "Recall =  0.6666666666666666\n",
      "Precision =  0.5\n",
      "\n",
      "\n",
      "Class 7\n",
      "\n",
      " True Pos  : 7     False Pos : 0\n",
      "\n",
      " False Neg : 2     True Neg  : 56\n",
      "\n",
      "\n",
      "Type =  7\n",
      "Recall =  0.7777777777777778\n",
      "Precision =  1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Accuracy            : 0.8872\n",
      "Precision           : 0.5874\n",
      "Recall              : 0.6365\n",
      "Macro F1            : 0.5897\n",
      "\n",
      "[[17  2  2  0  0  0]\n",
      " [ 6 13  0  3  1  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 1  0  0  0  2  0]\n",
      " [ 0  0  1  0  1  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Slightly more in-depth results\n",
    "recall = dict.fromkeys([1,2,3,5,6,7])\n",
    "precision = dict.fromkeys([1,2,3,5,6,7])\n",
    "f1 = dict.fromkeys([1,2,3,5,6,7])\n",
    "accuracies = []\n",
    "\n",
    "# Confusion matrix \n",
    "y_true = test.iloc[:]['type'].to_numpy()\n",
    "y_pred = np.zeros(shape=y_true.shape)\n",
    "for j in recall:\n",
    "    true_pos, true_neg, false_pos, false_neg = 0,0,0,0\n",
    "    for i in range(len(test.index)):\n",
    "        label = test.iloc[i]['type']\n",
    "        pred = list(classify(test.iloc[i],tree).keys())[0]\n",
    "        y_pred[i] = pred\n",
    "        if j == label:\n",
    "            if label == pred:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_neg += 1\n",
    "        else:\n",
    "            if j != pred:\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "    accuracies.append((true_pos + true_neg)/(true_pos + true_neg + false_neg + false_pos))\n",
    "    print(\"Class {}\".format(j))\n",
    "    print(\"\")\n",
    "    print(\" True Pos  : {}     False Pos : {}\".format(true_pos,false_pos))\n",
    "    print(\"\")\n",
    "    print(\" False Neg : {}     True Neg  : {}\".format(false_neg, true_neg))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    if true_pos + false_neg == 0:  # to fix scenarios where they equal 0\n",
    "        false_neg += 1\n",
    "    if true_pos + false_pos == 0:  # to fix scenarios where they equal 0\n",
    "        false_pos += 1\n",
    "\n",
    "    recall[j] = true_pos / (true_pos + false_neg)\n",
    "\n",
    "    precision[j] = true_pos / (true_pos + false_pos)\n",
    "    print(\"Type = \", j)\n",
    "    rec = recall[j]\n",
    "    print(\"Recall = \", rec)\n",
    "    pre = precision[j]\n",
    "    print(\"Precision = \", pre)\n",
    "    print(\"\")\n",
    "    print()\n",
    "        \n",
    "    if pre == 0:\n",
    "        f1[j] = 0\n",
    "    else:\n",
    "        f1[j]   = 2 * ((pre * rec) / (pre + rec))\n",
    "\n",
    "accuracy = sum(accuracies) / len(accuracies)\n",
    "macro_f1 = sum([f1[k] for k in [1,2,3,5,6,7]]) / 6\n",
    "recall_fin = sum([recall[k] for k in [1,2,3,5,6,7]]) / 6\n",
    "precision_fin = sum([precision[k] for k in [1,2,3,5,6,7]]) / 6\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Accuracy            : {}\".format(round(accuracy , 4)))\n",
    "print(\"Precision           : {}\".format(round(precision_fin,4)))\n",
    "print(\"Recall              : {}\".format(round(recall_fin,4)))\n",
    "print(\"Macro F1            : {}\".format(round(macro_f1,4)))\n",
    "print(\"\")\n",
    "#print(y_true)\n",
    "#print(y_pred)\n",
    "print(confusion_matrix(y_true, y_pred,labels=[1,2,3,5,6,7]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
