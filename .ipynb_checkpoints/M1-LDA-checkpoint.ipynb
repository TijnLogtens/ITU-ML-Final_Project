{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code derived from this example:\n",
    "\n",
    "https://towardsdatascience.com/an-illustrative-introduction-to-fishers-linear-discriminant-9484efee15ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_eigen_vectors(X_data, y_data):\n",
    "    rows , dimension = X_data.shape\n",
    "\n",
    "    data = np.hstack((X_data , y_data))\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.rename(columns={int(dimension):'class'},inplace=True)\n",
    "\n",
    "    # First we must calculate the mean-vector for each class C_i\n",
    "    class_feature_means = pd.DataFrame(columns= df['class'].unique())\n",
    "\n",
    "    for c, rows in df.groupby('class'):\n",
    "        class_feature_means[c] = rows.mean()\n",
    "\n",
    "    # Create within class scatter matrix\n",
    "    class_feature_means = class_feature_means.drop(['class'])\n",
    "\n",
    "    within_class_scatter_matrix = np.zeros((dimension,dimension))\n",
    "\n",
    "    # iterate through all the data in each class, to create the within_class_scatter_matrix\n",
    "    for c, rows in df.groupby('class'):\n",
    "        rows = rows.drop(['class'], axis=1) # removes the class from the dataframe\n",
    "        s = np.zeros((dimension,dimension))\n",
    "        for index, row in rows.iterrows():\n",
    "            x, mc = row.values.reshape(dimension,1),  class_feature_means[c].values.reshape(dimension,1)\n",
    "            s += (x - mc).dot((x - mc).T)\n",
    "        within_class_scatter_matrix += s\n",
    "\n",
    "    # Create between class scatter matrix\n",
    "    feature_means = df.drop('class',axis=1).mean()\n",
    "\n",
    "    between_class_scatter_matrix = np.zeros((dimension,dimension))\n",
    "\n",
    "    for c in class_feature_means:    \n",
    "        n = len(df.loc[df['class'] == c].index) # the number of values of class c\n",
    "        mc, m = class_feature_means[c].values.reshape(dimension,1), feature_means.values.reshape(dimension,1)        \n",
    "        between_class_scatter_matrix += n * (mc - m).dot((mc - m).T)\n",
    "\n",
    "    #print(\"Shape of within_class_scatter_matrix : \", within_class_scatter_matrix.shape)\n",
    "    #print(\"Shape of between_class_scatter_matrix : \", between_class_scatter_matrix.shape)\n",
    "\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(within_class_scatter_matrix).dot(between_class_scatter_matrix))\n",
    "\n",
    "    # Sorting pairs.\n",
    "    pairs = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\n",
    "    pairs = sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # returning eigen_vectors\n",
    "    sorted_eig_vectors = [tupll[1] for tupll in pairs] \n",
    "    # print(\"sorted_eig_vectors[0] : \", sorted_eig_vectors[0])\n",
    "    # print(\"sorted_eig_vectors[1] : \",sorted_eig_vectors[1])\n",
    "    # print(\"\")\n",
    "    # print(\"pairs[0][0]: \",pairs[0][0])\n",
    "    # print(\"pairs[1][0]: \",pairs[1][0])\n",
    "\n",
    "    return sorted_eig_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_from_weigths(X_data, eigen_vectors, new_dimension):\n",
    "    rows , old_dim = X_data.shape\n",
    "    #print('rows: ',rows,'       old dim: ',old_dim)\n",
    "    weights = np.zeros((old_dim,new_dimension))\n",
    "    for col_idx, eigen_vector in enumerate(eigen_vectors[ : new_dimension]):\n",
    "        for r_idx, weight in enumerate(eigen_vector):\n",
    "            #print(\"weight: \", weight)\n",
    "            weights[r_idx , col_idx] = weight\n",
    "\n",
    "    # eigen_vectors_to_use = np.array([i for i in eigen_vectors[ : new_dimension]])\n",
    "    # #print('eigen_vectors_to_use             ',eigen_vectors_to_use)\n",
    "    # #print(\"eigen_vectors_to_use.shape :\", eigen_vectors_to_use.shape)\n",
    "    # eigen_vectors_to_use = eigen_vectors_to_use.reshape(old_dim, new_dimension)\n",
    "    #print('reshaped eigen_vectors_to_use             ',eigen_vectors_to_use)\n",
    "\n",
    "    print(\"shape(Old_X_data) :\", X_data.shape)\n",
    "    New_X_data = X_data.dot(weights)\n",
    "    print(\"shape(New_X_data) :\", New_X_data.shape)\n",
    "\n",
    "    return New_X_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _LDA(X_train, X_test , y_train , output_dim, PCA = False):\n",
    "    pca_dim_out = X_train.shape[1]   # Default X_train.shape[1]\n",
    "    #pca_dim_out = 10                # bad results\n",
    "    \n",
    "    # Doing it for Train data\n",
    "    if PCA:\n",
    "        # Create PCA eigen vectors\n",
    "        pca_eig_vectors = PCA_eigen_vectors(X_train)\n",
    "        # call create_data_from_weigths()\n",
    "        X_train = create_data_from_weigths(X_train, pca_eig_vectors, pca_dim_out)\n",
    "        # Doing it for Test data (with the eigenvectors from Train on LDA)\n",
    "        # Create PCA eigen vectors\n",
    "        X_test = create_data_from_weigths(X_test, pca_eig_vectors, pca_dim_out)\n",
    "\n",
    "    # Create LDA eigen vectors\n",
    "    lda_eig_vectors = LDA_eigen_vectors(X_train, y_train)\n",
    "    # call create_data_from_weights()\n",
    "    new_X_data_train = create_data_from_weigths(X_train, lda_eig_vectors, output_dim)\n",
    "    print(\"shape of new_X_data_train: \", new_X_data_train.shape)\n",
    "\n",
    "    # Use eigenvectors from train set.\n",
    "    # This method assumes that the transformation with PCA is similar in both Train and Test\n",
    "    new_X_data_test = create_data_from_weigths(X_test, lda_eig_vectors, output_dim)\n",
    "    print(\"shape of new_X_data_test: \", new_X_data_test.shape)\n",
    "\n",
    "    # return 2 data sets in shape N,d , where N = (length of dataset), and d = (dimensionality)\n",
    "    return new_X_data_train, new_X_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_classes(y_train):\n",
    "    y_train = y_train.T\n",
    "    class_counter = set()\n",
    "    for label in y_train[0]:\n",
    "        class_counter.add(label)\n",
    "    amount_of_classes = len(class_counter)\n",
    "    return amount_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gauss_distribution(X_train, y_train):\n",
    "    num_of_classes = how_many_classes(y_train)\n",
    "\n",
    "    # Seperating the data with respect to labels. data_dict[0] contains a list of all isntances in class 0.\n",
    "    data_dict = {_class:[] for _class in range(num_of_classes)}\n",
    "    for idx,instance in enumerate(X_train):\n",
    "        data_dict[int(y_train[idx])].append(instance)\n",
    "\n",
    "    # Creating a dictionary for each class, with parameters for a multivariable gaussian distribution\n",
    "    dict_of_gauss_distributions = {c:{'mean': None , 'cov':None, 'prior':None} for c in range(num_of_classes)}\n",
    "    for c in range(num_of_classes):\n",
    "        n_dimensions = len(data_dict[0][0])\n",
    "        mean_vector = []\n",
    "        for dim in range(n_dimensions):\n",
    "            mean_vector.append (sum([ data_dict[c][enum][dim] for enum in range(len(data_dict[c])) ]) / len(data_dict[c]))\n",
    "        mean_vector = np.array(mean_vector).T\n",
    "\n",
    "        dict_of_gauss_distributions[c]['mean']  = mean_vector\n",
    "        dict_of_gauss_distributions[c]['cov']   = np.cov(np.array(data_dict[c]).T)\n",
    "        dict_of_gauss_distributions[c]['prior'] = len(data_dict[c]) / len(X_train)\n",
    "\n",
    "        # print('Class: ',c, ' mean_c: ', dict_of_gauss_distributions[c]['mean']) # np.array()\n",
    "        # print(\"  shape = {}\".format(dict_of_gauss_distributions[c]['mean'].shape))\n",
    "        # print(\"\")\n",
    "        # print('Class: ',c, ' cov_c: ',dict_of_gauss_distributions[c]['cov'])\n",
    "        # print(\"  shape = {}\".format(dict_of_gauss_distributions[c]['cov'].shape))\n",
    "        # print(\"\")\n",
    "        # print('Class: ',c, ' Prior : ', dict_of_gauss_distributions[c]['prior'])\n",
    "        # print('\\n')\n",
    "        # print('\\n')\n",
    "\n",
    "    # Return K gaussian distributions, where K = amount of classes.\n",
    "    return dict_of_gauss_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_of_x_given_Ck(x_instance , gauss_dist):\n",
    "    dim = len(x_instance)\n",
    "    mean = gauss_dist['mean'].reshape(dim,1) # Forcing a column vector\n",
    "    cov = gauss_dist['cov']\n",
    "    prior = gauss_dist['prior']\n",
    "    x_instance = x_instance.reshape(dim,1) # Forcing a column vector\n",
    "\n",
    "    scalar = (1 / ((2 * np.pi) ** (dim / 2))) * (1 / np.sqrt(np.linalg.det(cov)))\n",
    "\n",
    "    exponent = -1/2*((np.subtract(x_instance,mean)).T).dot((np.linalg.inv(cov)).dot(np.subtract(x_instance,mean)))\n",
    "    \n",
    "    ## P(Ck|x) =  P(x|Ck) * P(Ck)   <=>  scalar * np.exp(exponent) * prior = N(x|mu,cov), where x is a single instance\n",
    "\n",
    "    #return float((scalar * np.exp(exponent) * prior)[0][0])\n",
    "    return np.float64(scalar * np.exp(exponent) * prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(X_test,  y_test , gauss_distributions):\n",
    "    num_of_classes = how_many_classes(y_test)\n",
    "    # A list of predictions with same order as\n",
    "    predictions = []\n",
    "    for enum,instance in enumerate(X_test):\n",
    "        # For each instance, find the best probability of instance being a random variable in a gauss distribution.\n",
    "        best_class = None\n",
    "        best_prob_c_given_x = 0\n",
    "        for c in range(num_of_classes):\n",
    "            gauss_dist = gauss_distributions[c]\n",
    "            probs = proba_of_x_given_Ck(instance , gauss_dist)\n",
    "\n",
    "            # updating the best class\n",
    "            if probs >= best_prob_c_given_x:\n",
    "                best_prob_c_given_x = probs\n",
    "                best_class = c\n",
    "\n",
    "        predictions.append(best_class)  # appending the predicted label/class as an int.\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LDA_classifier(X_test, y_test, X_train, y_train, dim, PCA=False):    \n",
    "\n",
    "    # Projecting X_train and X_test with eigenvectors from X_train\n",
    "    X_train , X_test = _LDA(X_train, X_test , y_train , dim , PCA)\n",
    "    print(\" Projected data created \")\n",
    "    print(\" New projection dimensions used for classification:\", dim )\n",
    "\n",
    "    # Creating K gaussian distributions in for of a dictionary. (look at line 27 under create_gauss_distribution())\n",
    "    gauss_distributions = create_gauss_distribution(X_train, y_train)\n",
    "\n",
    "    # List of predictions in same order as y_test\n",
    "    predictions = predict_data(X_test, y_test , gauss_distributions)\n",
    "\n",
    "    # Calculating accuracy\n",
    "    recall_dict = {c : 0 for c in range(6)}\n",
    "    precision_dict = {c : 0 for c in range(6)}\n",
    "    f1_dict = {c : 0 for c in range(6)}\n",
    "    accuracies = []\n",
    "\n",
    "    for clss in recall_dict:\n",
    "        print(\"\")\n",
    "        print(\" Calculating values for Class {}\".format(clss))\n",
    "        print(\"\")\n",
    "        true_pos  = 0\n",
    "        true_neg  = 0\n",
    "        false_pos = 0\n",
    "        false_neg = 0\n",
    "        for idx in range(len(predictions)):\n",
    "            true_label = int(predictions[idx])\n",
    "            pred_label = int(y_test[idx][0])\n",
    "            #print(\" Label {}  VS. Prediction {}\".format(true_label,pred_label))\n",
    "            if clss == true_label:\n",
    "                if clss == pred_label:\n",
    "                    #print(\"true_pos\")\n",
    "                    true_pos += 1\n",
    "                else:\n",
    "                    #print(\"false_neg\")\n",
    "                    false_neg += 1\n",
    "            else:\n",
    "                if clss != pred_label:\n",
    "                    #print(\"true_neg\")\n",
    "                    true_neg += 1\n",
    "                else:\n",
    "                    false_pos += 1\n",
    "                    #print(\"false_pos\")\n",
    "        \n",
    "        \" ACC = ( True_pos + True_neg ) / ( False_pos + False_neg + True_pos + True_neg )\"\n",
    "        accuracies.append((true_pos + true_neg)/(true_pos + true_neg + false_neg + false_pos))\n",
    "        print(\"Class {}\".format(clss))\n",
    "        print(\"\")\n",
    "        print(\" True Pos  : {}     False Pos : {}\".format(true_pos,false_pos))\n",
    "        print(\"\")\n",
    "        print(\" False Neg : {}     True Neg  : {}\".format(false_neg, true_neg))\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "\n",
    "        if true_pos + false_neg == 0:  # to fix scenarios where they equal 0\n",
    "            false_neg += 1\n",
    "        if true_pos + false_pos == 0:  # to fix scenarios where they equal 0\n",
    "            false_pos += 1\n",
    "\n",
    "        recall_dict[clss]    = true_pos / (true_pos + false_neg)\n",
    "\n",
    "        precision_dict[clss] = true_pos / (true_pos + false_pos)\n",
    "        print(clss)\n",
    "        rec = recall_dict[clss]\n",
    "        print(rec)\n",
    "        pre = precision_dict[clss]\n",
    "        print(pre)\n",
    "        print(\"\")\n",
    "        print()\n",
    "        \n",
    "        if pre == 0:\n",
    "            f1_dict[clss] = 0\n",
    "        else:\n",
    "            f1_dict[clss]   = 2 * ((pre * rec) / (pre + rec))\n",
    "\n",
    "\n",
    "    accuracy = sum(accuracies) / len(accuracies)\n",
    "    macro_f1 = sum([f1_dict[label] for label in range(6)]) / 6\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\" Accuracy            : {}\".format(round(accuracy , 7)))\n",
    "    print(\" Macro F1            : {}\".format(round(macro_f1,4)))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\" ----- Class specific score -----\")\n",
    "    print(\"\")\n",
    "    for c in range(6):\n",
    "        print(\"             Class {}\".format(c))\n",
    "        print(\"             Precision   : {}\".format(round(precision_dict[c],4)))\n",
    "        print(\"             Recall      : {}\".format(round(recall_dict[c],4)))\n",
    "        print(\"             F1          : {}\".format(round(f1_dict[c],4)))\n",
    "        print(\"\")\n",
    "\n",
    "    return accuracy, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"df_train.csv\")\n",
    "df_test = pd.read_csv(\"df_test.csv\")\n",
    "\n",
    "df_train = df_train.replace({\"type\":1},0)\n",
    "df_train = df_train.replace({\"type\":2},1)\n",
    "df_train = df_train.replace({\"type\":3},2)\n",
    "df_train = df_train.replace({\"type\":5},3)\n",
    "df_train = df_train.replace({\"type\":6},4)\n",
    "df_train = df_train.replace({\"type\":7},5)\n",
    "\n",
    "df_test = df_test.replace({\"type\":1},0)\n",
    "df_test = df_test.replace({\"type\":2},1)\n",
    "df_test = df_test.replace({\"type\":3},2)\n",
    "df_test = df_test.replace({\"type\":5},3)\n",
    "df_test = df_test.replace({\"type\":6},4)\n",
    "df_test = df_test.replace({\"type\":7},5)\n",
    "\n",
    "\n",
    "#X = df_train[[\"RI\",\"Na\",\"Mg\",\"Al\",\"Si\",\"K\",\"Ca\",\"Ba\",\"Fe\"]].to_numpy()\n",
    "#y = np.array(df_train[\"type\"].to_numpy())\n",
    "\n",
    "X = df_train.to_numpy()[:,:-1]\n",
    "y = df_train.to_numpy()[:,-1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test = df_test.to_numpy()[:,:-1]\n",
    "y_test = df_test.to_numpy()[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(Old_X_data) : (149, 9)\n",
      "shape(New_X_data) : (149, 6)\n",
      "shape of new_X_data_train:  (149, 6)\n",
      "shape(Old_X_data) : (65, 9)\n",
      "shape(New_X_data) : (65, 6)\n",
      "shape of new_X_data_test:  (65, 6)\n",
      " Projected data created \n",
      " New projection dimensions used for classification: 6\n",
      "\n",
      " Calculating values for Class 0\n",
      "\n",
      "Class 0\n",
      "\n",
      " True Pos  : 18     False Pos : 3\n",
      "\n",
      " False Neg : 16     True Neg  : 28\n",
      "\n",
      "\n",
      "0\n",
      "0.5294117647058824\n",
      "0.8571428571428571\n",
      "\n",
      "\n",
      "\n",
      " Calculating values for Class 1\n",
      "\n",
      "Class 1\n",
      "\n",
      " True Pos  : 6     False Pos : 17\n",
      "\n",
      " False Neg : 5     True Neg  : 37\n",
      "\n",
      "\n",
      "1\n",
      "0.5454545454545454\n",
      "0.2608695652173913\n",
      "\n",
      "\n",
      "\n",
      " Calculating values for Class 2\n",
      "\n",
      "Class 2\n",
      "\n",
      " True Pos  : 3     False Pos : 2\n",
      "\n",
      " False Neg : 3     True Neg  : 57\n",
      "\n",
      "\n",
      "2\n",
      "0.5\n",
      "0.6\n",
      "\n",
      "\n",
      "\n",
      " Calculating values for Class 3\n",
      "\n",
      "Class 3\n",
      "\n",
      " True Pos  : 3     False Pos : 1\n",
      "\n",
      " False Neg : 1     True Neg  : 60\n",
      "\n",
      "\n",
      "3\n",
      "0.75\n",
      "0.75\n",
      "\n",
      "\n",
      "\n",
      " Calculating values for Class 4\n",
      "\n",
      "Class 4\n",
      "\n",
      " True Pos  : 0     False Pos : 3\n",
      "\n",
      " False Neg : 0     True Neg  : 62\n",
      "\n",
      "\n",
      "4\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "\n",
      " Calculating values for Class 5\n",
      "\n",
      "Class 5\n",
      "\n",
      " True Pos  : 8     False Pos : 1\n",
      "\n",
      " False Neg : 2     True Neg  : 54\n",
      "\n",
      "\n",
      "5\n",
      "0.8\n",
      "0.8888888888888888\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Accuracy            : 0.8615385\n",
      " Macro F1            : 0.5242\n",
      "\n",
      "\n",
      " ----- Class specific score -----\n",
      "\n",
      "             Class 0\n",
      "             Precision   : 0.8571\n",
      "             Recall      : 0.5294\n",
      "             F1          : 0.6545\n",
      "\n",
      "             Class 1\n",
      "             Precision   : 0.2609\n",
      "             Recall      : 0.5455\n",
      "             F1          : 0.3529\n",
      "\n",
      "             Class 2\n",
      "             Precision   : 0.6\n",
      "             Recall      : 0.5\n",
      "             F1          : 0.5455\n",
      "\n",
      "             Class 3\n",
      "             Precision   : 0.75\n",
      "             Recall      : 0.75\n",
      "             F1          : 0.75\n",
      "\n",
      "             Class 4\n",
      "             Precision   : 0.0\n",
      "             Recall      : 0.0\n",
      "             F1          : 0\n",
      "\n",
      "             Class 5\n",
      "             Precision   : 0.8889\n",
      "             Recall      : 0.8\n",
      "             F1          : 0.8421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-3d1d72c4a360>:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  weights[r_idx , col_idx] = weight\n",
      "<ipython-input-10-2d1736fc30f6>:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  scalar = (1 / ((2 * np.pi) ** (dim / 2))) * (1 / np.sqrt(np.linalg.det(cov)))\n",
      "<ipython-input-10-2d1736fc30f6>:15: RuntimeWarning: overflow encountered in exp\n",
      "  return np.float64(scalar * np.exp(exponent) * prior)\n"
     ]
    }
   ],
   "source": [
    "accuracy, macro_f1 = test_LDA_classifier(X_test, y_test, X, y, dimensions, PCA=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
