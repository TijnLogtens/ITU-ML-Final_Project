{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('seaborn')\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"df_train.csv\")\n",
    "df_test = pd.read_csv(\"df_test.csv\")\n",
    "\n",
    "df_train = df_train.replace({\"type\":1},0)\n",
    "df_train = df_train.replace({\"type\":2},1)\n",
    "df_train = df_train.replace({\"type\":3},2)\n",
    "df_train = df_train.replace({\"type\":5},3)\n",
    "df_train = df_train.replace({\"type\":6},4)\n",
    "df_train = df_train.replace({\"type\":7},5)\n",
    "\n",
    "df_test = df_test.replace({\"type\":1},0)\n",
    "df_test = df_test.replace({\"type\":2},1)\n",
    "df_test = df_test.replace({\"type\":3},2)\n",
    "df_test = df_test.replace({\"type\":5},3)\n",
    "df_test = df_test.replace({\"type\":6},4)\n",
    "df_test = df_test.replace({\"type\":7},5)\n",
    "\n",
    "\n",
    "X = df_train.to_numpy()[:,:-1]\n",
    "y = df_train.to_numpy()[:,-1:]\n",
    "\n",
    "\n",
    "X_test = df_test.to_numpy()[:,:-1]\n",
    "y_test = df_test.to_numpy()[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M0-EDA\n",
    "\n",
    "## Preliminary EDA\n",
    "\n",
    "For the EDA we started by checking the dymensions and distribution of our dataset. From our preliminary EDA we found the data set to be quite small and sparse. \n",
    "\n",
    "* insert plot here *\n",
    "\n",
    "When looking at a histogram of the class distributions, we see that they're quite uneven aswell. A data set with the dimensions of (200,9) is not neccesarily ideal for a 6 class classification. This might be compounded by the uneven distribution of the dataset as there is a higher risk for overfitting, when validation our models on an subsection of an already small dataset. There are ways of of combating this tendency towards overfitting though. \n",
    "\n",
    "## K-folds crossvalidation\n",
    "\n",
    "K-folds crossvalidation splits the dataset into K folds. It then goes through each split, using it as a validation set for the model and then generates K scores. We can then calculate the mean and variance of the scores to see how the model perfomed. This approach helps when we try to find the right hyperparameters for our models. It makes it less likely to choose a model that is biased towards the validation set. This is especially important with small, sparse and unevenly distributed datasets, as you're less likely to make a split in the dataset that lessens the datas integrity or even worse, completely omits a class. The amount of folds can also be treated as a hyperparameter, but the variance tends to get higher when introducing more folds when dealing with smaller datasets. \n",
    "\n",
    "## LDA plots\n",
    "\n",
    "The next thing we wanted to find out about our data is how the data is clustered. As we're using LDA as a classifications algorithm, we can plot the dimensionality reduction performed. We do this to both get a sence of what our results might be, but also to get a general idea of which classes might be more clustered or correlated with eachother. The LDA projection maximizes the seperation of our classes, so it should be able to show with accuracy how seperable our classes are from eachother. \n",
    "\n",
    "* Insert plot here * \n",
    "\n",
    "We can see from the projection, that the window classes are very clustered, which points toward the chemical makeup being very similar. This might be intuative as window glass has very similar attributes, being clearly seethrough, somewhat insulating and quite sturdy. When looking at the rest of our classes they are somewhat clustered, but they are very sparse and have some outlier values. This tells us that window classes might be harder to accuratly classify, and will have a lower precision, recall and f1 score, due to the clustering. The rest of the classes might be easier to classify if the model can take into acount their low frequency in the dataset. Anything naive-baise might have a hard time with this though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([49.,  0., 53.,  0., 12.,  0.,  9.,  0.,  6., 20.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53\n",
       "0    49\n",
       "5    20\n",
       "2    12\n",
       "3     9\n",
       "4     6\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
